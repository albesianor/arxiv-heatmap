{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22549bc0",
   "metadata": {},
   "source": [
    "# arXiv heatmap\n",
    "### Data cleaning\n",
    "\n",
    "##### Starting point\n",
    "- the arXiv metadata stripped of all columns except for `id` (`string`), `update_date` (`datetime`), and `categories` (`list`): `data/arxiv-metadata-id-categories.parquet`\n",
    "- the list of all current categories: `data/arxiv-categories.json`\n",
    "\n",
    "##### End goal\n",
    "A `pandas` dataframe:\n",
    "- indexed by `update_date`\n",
    "- with columns the 2x2 combinations of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2626dbf9",
   "metadata": {},
   "source": [
    "## The code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f84df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import copy\n",
    "from itertools import combinations_with_replacement as cwr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f4c75b",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce7b99",
   "metadata": {},
   "source": [
    "First we import the list of current arXiv category tags and store it in the list `arxiv_categories`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e84da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/arxiv-categories.json', 'r') as f:\n",
    "    arxiv_categories_descriptions = json.load(f)\n",
    "\n",
    "arxiv_categories = [cat['tag'] for cat in arxiv_categories_descriptions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90df65dc",
   "metadata": {},
   "source": [
    "Now we import the stripped data as `arxiv_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edf8a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_metadata = pd.read_parquet('../data/arxiv-metadata-id-date-categories.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73904746",
   "metadata": {},
   "source": [
    "The arXiv categories changed over the years: we find all categories that are not the current ones and store them in the set `missing_categories`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "214d84db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alg-geom', 'dg-ga', 'chem-ph', 'plasm-ph', 'ao-sci', 'mtrl-th', 'funct-an', 'comp-gas', 'q-alg', 'cond-mat', 'acc-phys', 'astro-ph', 'atom-ph', 'supr-con', 'chao-dyn', 'bayes-an', 'cmp-lg', 'q-bio', 'patt-sol', 'adap-org', 'solv-int'}\n"
     ]
    }
   ],
   "source": [
    "missing_categories = set()\n",
    "\n",
    "for index, row in arxiv_metadata.iterrows():\n",
    "    for category in row['categories']:\n",
    "        if category not in arxiv_categories:\n",
    "            missing_categories.add(category)\n",
    "\n",
    "print(missing_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee3d8e0",
   "metadata": {},
   "source": [
    "We need to decide what to do for each of the missing categories.  The most reasonable choice to me seems to find the closest matching current category and replace each missing category with that.\n",
    "\n",
    "| Old        |  New                | To add? |\n",
    "| ---------- | ------------------- | :-----: |\n",
    "| `mtrl-th`  | `cond-mat.mtrl-sci` |         |\n",
    "| `q-bio`    | `q-bio`             | X       |\n",
    "| `acc-phys` | `physics.acc-ph`    |         |\n",
    "| `dg-ga`    | `math.DG`           |         |\n",
    "| `cond-mat` | `cond-mat`          | X       |\n",
    "| `chem-ph`  | `physics.chem-ph`   |         |\n",
    "| `astro-ph` | `astro-ph`          | X       |\n",
    "| `comp-gas` | `nlin.CG`           |         |\n",
    "| `funct-an` | `math.FA`           |         |\n",
    "| `patt-sol` | `nlin.PS`           |         |\n",
    "| `solv-int` | `nlin.SI`           |         |\n",
    "| `alg-geom` | `math.AG`           |         |\n",
    "| `adap-org` | `nlin.AO`           |         |\n",
    "| `supr-con` | `cond-mat.supr-con` |         |\n",
    "| `plasm-ph` | `physics.plasm-ph`  |         |\n",
    "| `chao-dyn` | `nlin.CD`           |         |\n",
    "| `bayes-an` | `physics.data-an`   |         |\n",
    "| `q-alg`    | `math.QA`           |         |\n",
    "| `ao-sci`   | `physics.ao-ph`     |         |\n",
    "| `atom-ph`  | `physics.atom-ph`   |         |\n",
    "| `cmp-lg`   | `cs.CL`             |         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9164d30b",
   "metadata": {},
   "source": [
    "The categories `q-bio`, `cond-mat`, and `astro-ph` have been over the years split into subcategories.  Hence, some preprints are classified into what are now meta-categories.  We add these three categories, and we will use them only for those preprints dating to before the splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2579ee69",
   "metadata": {},
   "source": [
    "We then create a dictionary `graph_edges` whose keys are the tuples (with repetitions) of `arxiv_categories_extra` and whose entries represent the daily entries in that cross-listing (the tuple with repetition are the papers listed in only one category)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fbf89e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_categories_extra = arxiv_categories + ['q-bio', 'cond-mat', 'astro-ph']\n",
    "arxiv_categories_combinations = cwr(arxiv_categories_extra, 2)\n",
    "\n",
    "# use sorted to make sure the tuples are in a consistent ordering\n",
    "graph_edges = {tuple(sorted(index)): 0 for index in arxiv_categories_combinations}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead670c1",
   "metadata": {},
   "source": [
    "Now `arxiv_categories_extra` contains the current categories plus the three legacy meta-categories, and `graph_edges` has been updated to include the three new nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8daf74",
   "metadata": {},
   "source": [
    "We finally go through `arxiv_metadata` again and replace the missing categories with the new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb19bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a943de94",
   "metadata": {},
   "source": [
    "### Data crunching\n",
    "The goal now is to produce a new dataframe, indexed by `update_date` whose rows are the cross-listings.  We also want another dataframe containing the total daily publications in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f04ea67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
