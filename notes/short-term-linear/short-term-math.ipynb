{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144f2fe6",
   "metadata": {},
   "source": [
    "# arXiv heatmaps\n",
    "\n",
    "We try to predict the `math` totals only.  First we import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7daa48b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "full_df = pd.read_parquet(\"../../data/arxiv-totals.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908b2e6d",
   "metadata": {},
   "source": [
    "Then we sum all the `math` categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b26df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    pd.DataFrame(full_df[list(full_df.filter(regex=\"math.\"))].sum(axis=1))\n",
    "    .reset_index(inplace=False)\n",
    "    .rename(columns={\"date\": \"ds\", 0: \"y\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1369c37",
   "metadata": {},
   "source": [
    "One-hot encode weekday and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e8a5b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calendar import day_name\n",
    "\n",
    "df[\"weekday\"] = df[\"ds\"].apply(lambda date: day_name[date.weekday()])\n",
    "df[\"month\"] = df[\"ds\"].apply(lambda date: date.month)\n",
    "\n",
    "one_hot_weekday = (\n",
    "    pd.get_dummies(df.weekday, dtype=int).drop(\"Friday\", axis=1).iloc[:, [0, 2, 3, 1]]\n",
    ")\n",
    "one_hot_month = pd.get_dummies(df.month, dtype=int).drop(12, axis=1)\n",
    "df = df.join(one_hot_weekday).join(one_hot_month)\n",
    "\n",
    "df.columns = df.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592c0d4c",
   "metadata": {},
   "source": [
    "Make the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f59101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[\n",
    "    (df.ds >= pd.Timestamp(2001, 1, 1)) & (df.ds <= pd.Timestamp(2025, 3, 14))\n",
    "]\n",
    "df_test = df[df.ds >= pd.Timestamp(2025, 3, 17)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082ac28a",
   "metadata": {},
   "source": [
    "## The models with 150 days window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2df82ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "ts_cv = TimeSeriesSplit(n_splits=5, test_size=15, max_train_size=150)\n",
    "\n",
    "splits = list(ts_cv.split(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:18:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:18:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:18:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:18:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:18:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:18:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:18:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:18:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:18:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:18:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "dummy = DummyRegressor(strategy=\"mean\")\n",
    "t_reg = LinearRegression()\n",
    "day_reg = LinearRegression()\n",
    "mday_reg = LinearRegression()\n",
    "tday_reg = LinearRegression()\n",
    "gbrt = HistGradientBoostingRegressor(categorical_features=[\"weekday\", \"month\"])\n",
    "\n",
    "dummy_rmses = np.zeros(5)\n",
    "t_rmses = np.zeros(5)\n",
    "day_rmses = np.zeros(5)\n",
    "mday_rmses = np.zeros(5)\n",
    "tday_rmses = np.zeros(5)\n",
    "gbrt_rmses = np.zeros(5)\n",
    "prophet_rmses = np.zeros(5)\n",
    "\n",
    "with open(\"../../data/arxiv-categories.json\", \"r\") as f:\n",
    "    arxiv_categories_descriptions = json.load(f)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    # prepare train data\n",
    "    df_tt = df_train.iloc[train_index, :]\n",
    "    df_tt.reset_index(\n",
    "        inplace=True\n",
    "    )  # reset index twice to get a column of indexes to use as feature\n",
    "\n",
    "    # prepare validation data\n",
    "    df_holdout = df_train.iloc[test_index, :]\n",
    "    df_holdout.reset_index(inplace=True)\n",
    "\n",
    "    # dummy model\n",
    "    dummy.fit(df_tt[[\"index\"]], df_tt[\"y\"])\n",
    "    dummy_preds = dummy.predict(df_holdout[[\"index\"]])\n",
    "    dummy_rmses[i] = root_mean_squared_error(df_holdout[\"y\"], dummy_preds)\n",
    "\n",
    "    # t-linear model\n",
    "    t_reg.fit(df_tt[[\"index\"]], df_tt[\"y\"])\n",
    "    t_preds = t_reg.predict(df_holdout[[\"index\"]])\n",
    "    t_rmses[i] = root_mean_squared_error(df_holdout[\"y\"], t_preds)\n",
    "\n",
    "    # day-linear model\n",
    "    day_reg.fit(df_tt[[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\"]], df_tt[\"y\"])\n",
    "    day_preds = day_reg.predict(\n",
    "        df_holdout[[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\"]]\n",
    "    )\n",
    "    day_rmses[i] = root_mean_squared_error(df_holdout[\"y\"], day_preds)\n",
    "\n",
    "    # day-linear model\n",
    "    mday_reg.fit(\n",
    "        df_tt[\n",
    "            [\n",
    "                \"1\",\n",
    "                \"2\",\n",
    "                \"3\",\n",
    "                \"4\",\n",
    "                \"5\",\n",
    "                \"6\",\n",
    "                \"7\",\n",
    "                \"8\",\n",
    "                \"9\",\n",
    "                \"10\",\n",
    "                \"11\",\n",
    "                \"Monday\",\n",
    "                \"Tuesday\",\n",
    "                \"Wednesday\",\n",
    "                \"Thursday\",\n",
    "            ]\n",
    "        ],\n",
    "        df_tt[\"y\"],\n",
    "    )\n",
    "    mday_preds = mday_reg.predict(\n",
    "        df_holdout[\n",
    "            [\n",
    "                \"1\",\n",
    "                \"2\",\n",
    "                \"3\",\n",
    "                \"4\",\n",
    "                \"5\",\n",
    "                \"6\",\n",
    "                \"7\",\n",
    "                \"8\",\n",
    "                \"9\",\n",
    "                \"10\",\n",
    "                \"11\",\n",
    "                \"Monday\",\n",
    "                \"Tuesday\",\n",
    "                \"Wednesday\",\n",
    "                \"Thursday\",\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "    mday_rmses[i] = root_mean_squared_error(df_holdout[\"y\"], mday_preds)\n",
    "\n",
    "    # tday-linear model\n",
    "    tday_reg.fit(\n",
    "        df_tt[[\"index\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\"]],\n",
    "        df_tt[\"y\"],\n",
    "    )\n",
    "    tday_preds = tday_reg.predict(\n",
    "        df_holdout[[\"index\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\"]]\n",
    "    )\n",
    "    tday_rmses[i] = root_mean_squared_error(df_holdout[\"y\"], tday_preds)\n",
    "\n",
    "    # gradient boosting\n",
    "    gbrt.fit(df_tt[[\"weekday\", \"month\"]], df_tt[\"y\"])\n",
    "    gbrt_preds = gbrt.predict(df_holdout[[\"weekday\", \"month\"]])\n",
    "    gbrt_rmses[i] = root_mean_squared_error(df_holdout[\"y\"], gbrt_preds)\n",
    "\n",
    "    # prophet\n",
    "    prophet = Prophet()\n",
    "    prophet.fit(df_tt)\n",
    "    prophet_preds = prophet.predict(df_holdout[[\"ds\"]])[\"yhat\"]\n",
    "    prophet_rmses[i] = root_mean_squared_error(df_holdout[\"y\"], prophet_preds)\n",
    "    del prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490dfb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy rmses: [ 66.39552361 118.07022317  54.14753549  69.10937418  66.50741011]\n",
      "  - mean =  74.8460133146663\n",
      "Linear reg rmses: [ 63.96316405 123.01287056  56.94975938  68.69509773  65.543826  ]\n",
      "  - mean =  75.63294354560354\n",
      "Weekday reg rmses: [38.40085358 84.14185113 23.20612467 30.6547948  29.04687782]\n",
      "  - mean =  41.09010040000369\n",
      "Month-weekday reg rmses: [38.3335876  93.19557312 50.6747524  31.57441748 25.39006715]\n",
      "  - mean =  47.833679549633366\n",
      "Linear-weekday reg rmses: [32.64566846 91.97123533 30.90189787 29.51103125 26.16828907]\n",
      "  - mean =  42.23962439642128\n",
      "Gradient boosting rmses: [35.55291677 90.24905791 44.90067874 31.53571178 28.67952289]\n",
      "  - mean =  46.183577617612926\n",
      "Prophet rmses: [30.61248243 99.7677942  23.39373717 33.06705749 31.86888653]\n",
      "  - mean =  43.741991564849535\n"
     ]
    }
   ],
   "source": [
    "print(\"Dummy rmses:\", dummy_rmses)\n",
    "print(\"  - mean = \", dummy_rmses.mean())\n",
    "print(\"Linear reg rmses:\", t_rmses)\n",
    "print(\"  - mean = \", t_rmses.mean())\n",
    "print(\"Weekday reg rmses:\", day_rmses)\n",
    "print(\"  - mean = \", day_rmses.mean())\n",
    "print(\"Month-weekday reg rmses:\", mday_rmses)\n",
    "print(\"  - mean = \", mday_rmses.mean())\n",
    "print(\"Linear-weekday reg rmses:\", tday_rmses)\n",
    "print(\"  - mean = \", tday_rmses.mean())\n",
    "print(\"Gradient boosting rmses:\", gbrt_rmses)\n",
    "print(\"  - mean = \", gbrt_rmses.mean())\n",
    "print(\"Prophet rmses:\", prophet_rmses)\n",
    "print(\"  - mean = \", prophet_rmses.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb7cd7",
   "metadata": {},
   "source": [
    "## Full FB Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcaefa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:24:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "ts_cv = TimeSeriesSplit(n_splits=5, test_size=15)\n",
    "\n",
    "splits = list(ts_cv.split(df_train))\n",
    "\n",
    "prophet_full_rmses = np.zeros(5)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    # prepare train data\n",
    "    df_tt = df_train.iloc[train_index, :]\n",
    "\n",
    "    # prepare validation data\n",
    "    df_holdout = df_train.iloc[test_index, :]\n",
    "\n",
    "    # prophet\n",
    "    prophet = Prophet()\n",
    "    prophet.fit(df_tt)\n",
    "    prophet_preds = prophet.predict(df_holdout[[\"ds\"]])[\"yhat\"]\n",
    "    prophet_full_rmses[i] = root_mean_squared_error(df_holdout[\"y\"], prophet_preds)\n",
    "    del prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dfcadd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy rmses: [ 66.39552361 118.07022317  54.14753549  69.10937418  66.50741011]\n",
      "  - mean =  74.8460133146663\n",
      "Linear reg rmses: [ 63.96316405 123.01287056  56.94975938  68.69509773  65.543826  ]\n",
      "  - mean =  75.63294354560354\n",
      "Weekday reg rmses: [38.40085358 84.14185113 23.20612467 30.6547948  29.04687782]\n",
      "  - mean =  41.09010040000369\n",
      "Month-weekday reg rmses: [38.3335876  93.19557312 50.6747524  31.57441748 25.39006715]\n",
      "  - mean =  47.833679549633366\n",
      "Linear-weekday reg rmses: [32.64566846 91.97123533 30.90189787 29.51103125 26.16828907]\n",
      "  - mean =  42.23962439642128\n",
      "Gradient boosting rmses: [35.55291677 90.24905791 44.90067874 31.53571178 28.67952289]\n",
      "  - mean =  46.183577617612926\n",
      "Prophet rmses: [30.61248243 99.7677942  23.39373717 33.06705749 31.86888653]\n",
      "  - mean =  43.741991564849535\n",
      "Full prophet rmses: [45.69470014 94.34975619 32.95994785 46.53997394 43.85623571]\n",
      "  - mean =  52.68012276829133\n"
     ]
    }
   ],
   "source": [
    "print(\"Dummy rmses:\", dummy_rmses)\n",
    "print(\"  - mean = \", dummy_rmses.mean())\n",
    "print(\"Linear reg rmses:\", t_rmses)\n",
    "print(\"  - mean = \", t_rmses.mean())\n",
    "print(\"Weekday reg rmses:\", day_rmses)\n",
    "print(\"  - mean = \", day_rmses.mean())\n",
    "print(\"Month-weekday reg rmses:\", mday_rmses)\n",
    "print(\"  - mean = \", mday_rmses.mean())\n",
    "print(\"Linear-weekday reg rmses:\", tday_rmses)\n",
    "print(\"  - mean = \", tday_rmses.mean())\n",
    "print(\"Gradient boosting rmses:\", gbrt_rmses)\n",
    "print(\"  - mean = \", gbrt_rmses.mean())\n",
    "print(\"Prophet rmses:\", prophet_rmses)\n",
    "print(\"  - mean = \", prophet_rmses.mean())\n",
    "print(\"Full prophet rmses:\", prophet_full_rmses)\n",
    "print(\"  - mean = \", prophet_full_rmses.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d8bafc",
   "metadata": {},
   "source": [
    "It looks like the best model is still just regression on one-hot encoded weekdays."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv-heatmaps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
